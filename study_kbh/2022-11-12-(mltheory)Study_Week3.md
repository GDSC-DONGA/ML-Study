---
typora-root-url: ../
---

## Intro

**머신러닝 이론을 공부하겠습니다.**

* 참고 URL
  * [머신러닝 이론](https://www.w3schools.com/python/python_ml_getting_started.asp)

<br>

## ML Theory

* 머신러닝은 컴퓨터가 데이터와 통계를 학습하도록 하는 것입니다.

* 머신러닝은 인공 지능(AI)으로 나아가는 단계입니다.

* 머신러닝은 데이터를 분석하고 결과를 예측하는 방법을 학습하는 프로그램입니다.
* 매우 큰 데이터 집합을 작업하는 것이 일반적입니다.



### Data Types

데이터 분석을 위해 어떤 유형의 데이터를 다루는지 아는 것이 중요합니다.  
보통 세 가지 범주로 나눌 수 있습니다.

* Numerical(수치)
* Categorical(카테고리)
* Ordinal(순서)



### Mean Median Mode

머신러닝에는 보통 세 가지 가치가 있습니다.

* Mean
* Median
* Mode(일반적인 값)



### Standard Deviation(표준 편차)

표준 편차는 편차의 평균을 의미합니다. 그리고 편차는 측정값과 평균값의 차이입니다.  
따라서 표준 편차는 값이 얼마나 퍼져 있는지 설명하는 숫자입니다.

* 표준 편차가 작은 경우 : 값들이 평균값에 가깝다는 것을 의미
* 표준 편차가 큰 경우 : 값들이 평균값과 멀다는 의미(값들이 더 넓은 범위에 퍼져있음)



### Percentiles(백분위수)

백분위수는 통계에서 주어진 값의 백분율이 더 낮은 값을 설명하는 숫자를 제공하는 데 사용됩니다.

아래 예시는 연령 데이터인 ages의 75%가 43세 이하임을 의미합니다.

```python
import numpy
ages = [5,31,43,48,50,41,7,11,15,39,80,82,32,2,8,6,25,36,27,61,31]
x = numpy.percentile(ages, 75)
print(x) # 43 ->백분위수
```



### Data Distribution(데이터 분포)

데이터분포란 데이터가 제각각인 수치로 나타나는 것을 의미합니다.

이러한 데이터 분포의 특징을 설명하기 위해 평균값, 표준편차 등이 활용됩니다.



### Normal Data Distribution(정규 데이터 분포)

가우스 데이터 분포라고도 부릅니다.

특징은 주어진 값(평균값) 주위에 값이 집중되는 형태를 만들 수 있습니다.



### Scatter Plot(산점도)

산점도는 데이터 세트의 각 값이 점으로 표시되는 다이어그램입니다.

(x,y)에 대해 그림을 그려 그 관계를 눈으로 쉽게 파악 할 수 있습니다.



### Linear Regression(선형 회귀)

변수 간의 관계를 찾으려고 할 때 사용됩니다. 이를 통해서 미래 값을 예측할 수 있으며, 선형이므로 직선을 그려가며 구하게 됩니다.



### Polynomial Regression(다항식 회귀)

선형 회귀에서 직선을 그려갔다면 다항식 회귀는 곡선의 형태를 그려가며 미래 값을 예측할 수 있습니다.

* 예로 다항식 회귀를 사용하는 코드입니다.(총 18대의 차량 데이터)

  * x, y데이터는 차량의 속도와 추월이 발생한 시각을 의미합니다.

  ```python
  import numpy
  import matplotlib.pyplot as plt
  
  x = [1,2,3,5,6,7,8,9,10,12,13,14,15,16,18,19,21,22]
  y = [100,90,80,60,60,55,60,65,70,70,75,76,78,79,90,99,99,100]
  
  mymodel = numpy.poly1d(numpy.polyfit(x, y, 3))
  
  myline = numpy.linspace(1, 22, 100) # x축 시간(1~22), y축 속도(1~100)
  
  plt.scatter(x, y) # x, y 데이터를 산점도로 보여줌
  plt.plot(myline, mymodel(myline)) # 다항식 회귀선
  plt.show()
  ```

<img src="./images/2022-11-12-(mltheory)Study_Week3/image-20221112202621800.png" alt="image-20221112202621800" style="zoom:50%;" />

* 중요한 것은 x,y가 관계가 있어야 합니다. 관계가 없는경우 올바른 예측값을 구할 수 없습니다.

  <img src="./images/2022-11-12-(mltheory)Study_Week3\image-20221112202825763.png" alt="image-20221112202825763" style="zoom:50%;" />

* 마지막으로 이러한 관계를 알아보는 방법이 있습니다.  
  r-제곱이라는 값으로 구해주며 이를 Python에서 제공합니다.

  ```python
  # 해당 예시는 바로 위의 그래프의 관계를 구한 예 입니다.
  import numpy
  from sklearn.metrics import r2_score
  
  x = [89,43,36,36,95,10,66,34,38,20,26,29,48,64,6,5,36,66,72,40]
  y = [21,46,3,35,67,95,53,72,58,10,26,34,90,33,38,20,56,2,47,15]
  
  mymodel = numpy.poly1d(numpy.polyfit(x, y, 3))
  
  print(r2_score(y, mymodel(x))) # 0.00995..로 낮은 관계
  ```

  

### Multiple Regression(다중 회귀)

다중 회귀는 선형 회귀와 유사하지만 둘 이상의 독립 값을 사용하므로 둘 이상의 변수를 기반으로 값을 예측을 합니다.

* 구하는 방법은 선형 회귀 메소드를 활용합니다.
* 다만, 이때 X값에 둘 이상의 변수를 넣어서 하는것이 특징입니다.



### Scale(규모)

데이터의 값이 다르고 측정 단위가 다를 경우의 해결법이 스케일링 입니다.  
데이터를 비교하기 쉬운 새 값으로 확장할 수 있습니다.

* 예로 부피 1.0과 무게 790을 비교하는 것은 어려울 수 있지만 둘 다 비슷한 값으로 확장하면 한 값이 다른 값과 얼마나 비교되는지 쉽게 알 수 있습니다.
* 정규화 공식을 사용해 줍니다.(다양한 방법이 있습니다)
  * `z = (x-u) / s`
  * z는 새로운 값, x는 원래 값, u는 평균 값, s는 표준 편차
  * 기존 790, 1.0에서 -2.1과 -1.59로 바뀌며 이 두값을 비교할 수 있게 됩니다.
* 위 과정을 `StandardScaler()` 메소드를 사용해서 구할 수 있습니다.



### Train/Test(훈련/시험)

훈련/테스트는 모델의 정확도를 측정하는 방법입니다.   
데이터를 훈련 세트와 테스트 세트의 두 세트로 분할하기 때문에 훈련/테스트라고 합니다.

* 훈련 세트는 원본 데이터의 80%를 무작위로 선택해야 합니다.   
  테스트 세트는 나머지 20%여야 합니다.
* 이를 통해서 원본 데이터와 유사하게 보이는지 판단을 통해서 모델의 정확도를 측정할 수 있습니다.



### Decision Tree(결정 트리)

의사 결정 트리는 순서도이며 이전 경험을 기반으로 **결정을 내리는 데 도움**이 될 수 있습니다.



### Confusion Matrix(혼란 매트릭스)

분류 문제에서 모델의 오류가 발생한 위치를 평가하는 데 사용되는 테이블입니다.   
행은 결과가 있어야 하는 실제 값을 나타냅니다. 열은 우리가 만든 예측 값을 나타냅니다. 

이 표를 사용하면 **어떤 예측이 잘못된 것인지 쉽게 알 수 있습니다.**

* `confusion_matrix` 메소드를 사용해서 혼란 매트릭스를 사용할 수 있습니다.



### Hierarchical Clustering(계층적 클러스터링)

계층적 클러스터링은 `비지도 학습`이므로 모델을 훈련할 필요가 없습니다.  
데이터 간의 유사성을 측정하여 클러스터를 구축합니다.

* 참고 : 클러스터란 하나의 집합처럼 밀접해있는 다수의 무언가를 총칭합니다.
* 예로 응집 클러스터링의 동작 원리는  
  * 각 데이터 자체를 클러스터로 먼저 취급합니다.  
  * 그다음 거리가 가장 짧은 클러스터 끼리 결합하여 더 큰 클러스터를 만들어 나갑니다.



### Logistic Regression(로지스틱 회귀)

로지스틱 회귀는 분류 문제를 해결하는 것을 목표로 합니다.   
연속 결과를 예측하는 선형 회귀와 달리 범주형 결과를 예측하여 이를 수행합니다. 

가장 단순한 경우에는 이항이라고 하는 두 가지 결과가 있으며,   
그 예는 종양이 악성인지 양성인지 예측하는 것입니다. 

* `LogisticRegression()` 메소드를 제공하고 있습니다.



### Categorical Data

데이터에 문자열로 표시되는 범주가 있는 경우, 종종 숫자 데이터만 허용하는 기계 학습 모델을 훈련하는 데 이를 사용하기 어려울 것입니다.   
범주형 데이터를 무시하고 모델에서 정보를 제외하는 대신 모델에서 사용할 수 있도록 데이터를 변환할 수 있습니다. 

* 이런 문자열 데이터를 열로 구분지어 나타내는 방법으로 Hot Encoding을 합니다.
  * 이를 지원해주는 `get_dummies()` 메소드를 활용할 수 있습니다.



### K-means

K-means는 데이터를 클러스터링하기 위한 `비지도 학습` 방법입니다.   
알고리즘은 각 클러스터의 거리 차이의 분산을 최소화하여 데이터를 K 클러스터로 반복적으로 나눕니다. 

* `KMeans` 클래스를 활용해서 간단히 구할 수 있습니다.



### K-nearest neighbors (KNN)

KNN은 분류 또는 회귀 작업에 사용할 수 있는 간단한 감독 기계 학습(ML) 알고리즘입니다.  
새로 들어온 값이 기존 값으로 이루어진 그룹의 데이터와 가장 가까우니 새로 들어온 값은 해당 그룹이라고 분류하는 알고리즘입니다.

K는 사용할 최근접이웃의 수입니다. 분류의 경우 과반수 투표는 새 관찰이 속하는 클래스를 결정하는 데 사용됩니다.   
더 큰 K 값은 종종 이상값에 대해 더 강력하고, 매우 작은 값보다 더 안정적인 결정 경계를 생성합니다.

* `KNeighborsClassifier` 클래스를 활용합니다.

* K는 몇 번째로 가까운 데이터까지 살펴볼지 정한 숫자입니다.

* K=1의 경우

  ```python
  from sklearn.neighbors import KNeighborsClassifier
  
  data = list(zip(x, y))
  knn = KNeighborsClassifier(n_neighbors=1) # K=1로 설정
  
  knn.fit(data, classes)
  
  # 아래는 새로운 값
  new_x = 8
  new_y = 21
  new_point = [(new_x, new_y)]
  
  prediction = knn.predict(new_point) # knn 사용
  
  plt.scatter(x + [new_x], y + [new_y], c=classes + [prediction[0]])
  plt.text(x=new_x-1.7, y=new_y-0.7, s=f"new point, class: {prediction[0]}")
  plt.show()
  ```

<img src="./images/2022-11-12-(mltheory)Study_Week3\image-20221112214812376.png" alt="image-20221112214812376" style="zoom:50%;" />

* `class: 0` 그룹으로 선정된 모습이다.



### 나머지

* Grid Search

* Bootstrap Aggregation (Bagging)
* Cross Validation
* AUC - ROC Curve

